name: Deploy to AWS Lambda

on:
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  build-and-deploy:
    name: Build package and deploy to Lambda
    runs-on: ubuntu-latest
    env:
      AWS_ROLE_TO_ASSUME: ${{ secrets.AWS_ROLE_TO_ASSUME }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - name: Install dependencies into package dir
        run: |
          set -e
          rm -rf package || true
          mkdir package
          # Exclude heavy libraries that are already available in Lambda or can be reduced
          # pandas and pyarrow are very large. We should try to use a Lambda Layer or exclude them if possible.
          # For now, let's try to install without dependencies for boto3 (it's in Lambda runtime)
          # and use --no-deps for some if needed, but pip install -t installs everything.
          
          # Strategy: Install requirements but remove heavy stuff that might not be needed or use layers.
          # However, pandas IS needed. The issue is the size limit (50MB zipped direct upload).
          
          pip install --upgrade -r requirements.txt --target package
          
          # Cleanup to reduce size
          cd package
          find . -type d -name "tests" -exec rm -rf {} +
          find . -type d -name "__pycache__" -exec rm -rf {} +
          rm -rf *.dist-info *.egg-info
          
          # Boto3 and botocore are included in the AWS Lambda Python runtime.
          # Removing them saves significant space (~50MB+ unzipped).
          rm -rf boto3* botocore* s3transfer*
          cd ..

      - name: Copy project files into package
        run: |
          # Copy your script(s) so that ingest_b3.py is at the root of the zip
          cp -r scripts/* package/ || true
          # If you have other modules or folders that the function needs, copy them too

      - name: Zip package contents
        run: |
          cd package
          # Zip the CONTENTS of package so files are at the zip root (important for Lambda handler)
          zip -r ../function.zip . -x "*.pyc" "__pycache__/*"
          cd ..
          ls -lh function.zip

      - name: Debug Auth Configuration
        run: |
          echo "Checking authentication configuration..."
          if [ -z "$AWS_ROLE_TO_ASSUME" ]; then
            echo "AWS_ROLE_TO_ASSUME is empty. Workflow will attempt to use Access Keys."
          else
            echo "AWS_ROLE_TO_ASSUME is set. Workflow will attempt to use OIDC."
          fi
          
          # Check if region is set (without printing secret if it was one, though region usually isn't)
          if [ -z "${{ secrets.AWS_REGION }}" ]; then
             echo "WARNING: AWS_REGION secret is empty!"
          else
             echo "AWS_REGION is set."
          fi

      - name: Configure AWS credentials (assume role via OIDC)
        if: env.AWS_ROLE_TO_ASSUME != ''
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Configure AWS credentials (access key fallback)
        if: env.AWS_ROLE_TO_ASSUME == ''
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Verify AWS identity
        run: aws sts get-caller-identity

      - name: Update Lambda function code
        env:
          LAMBDA_NAME: ${{ secrets.LAMBDA_FUNCTION_NAME }}
        run: |
          if [ -z "${LAMBDA_NAME}" ]; then
            echo "ERROR: Set the secret LAMBDA_FUNCTION_NAME"
            exit 1
          fi
          # If the file is still too large (>50MB), we should use S3, but let's try direct upload first after cleanup.
          aws lambda update-function-code --function-name "${LAMBDA_NAME}" --zip-file fileb://function.zip

      - name: Confirm deployment
        env:
          LAMBDA_NAME: ${{ secrets.LAMBDA_FUNCTION_NAME }}
        run: |
          aws lambda get-function --function-name "${LAMBDA_NAME}" --query 'Configuration.[FunctionName,LastModified,Runtime]' --output table

    # Notes:
    # - To use the OIDC flow, create an IAM Role with a trust relationship that allows
    #   GitHub's OIDC provider to assume it. Store the role ARN in the secret AWS_ROLE_TO_ASSUME.
    # - If you prefer static keys, set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY in repo secrets.
    # - For improved security, prefer the OIDC flow and grant only the specific S3/Lambda permissions needed.
